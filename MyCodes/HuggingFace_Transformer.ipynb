{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCeyUHlJ1FKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0598e17-3a4f-4e0b-fa66-9bb85f50672c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.10/dist-packages (3.4.3)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformer\n",
        "!pip install datasets\n",
        "!pip install tokenizer\n",
        "!pip install seqeval\n",
        "\n",
        "#!pip install transformer datasets tokenizer seqeval -q\n",
        "# download everything in single sort.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "OZ3ixj3G73T5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003 = datasets.load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1nLW6DnE0S1",
        "outputId": "1bda38e6-4ecb-4504-b48e-2a06f3bc7936"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BnkV1_pFGjp",
        "outputId": "72dad62a-45cb-4b94-fcf8-6d2a1c983dfa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7WhqD25G8r1",
        "outputId": "6545c7d1-2546-4d51-b27b-e2933b548503"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS:- Part of speech\n",
        "ner:- name entity recoginisation"
      ],
      "metadata": {
        "id": "hY3dKGkrIx5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003[\"train\"].features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_-ymyDNH4_G",
        "outputId": "4f080623-a07f-4f94-c1d1-54f206e0cd61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003[\"train\"].description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "I-k9aCElIgQK",
        "outputId": "4b1cca7f-07db-4b66-9278-fc6341aa86b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "Pa62AegaKi9V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = conll2003[\"train\"][0]"
      ],
      "metadata": {
        "id": "IF9Am4rmCYK_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ7Ej62jDJ5N",
        "outputId": "b8fd0e09-b5bf-422d-8e42-1f1b3e62b9f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)"
      ],
      "metadata": {
        "id": "mDob2pAmDnim"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUYShjXkES4I",
        "outputId": "7c4f236b-612d-437f-e171-8c3303d49616"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwHL_n9mEfPK",
        "outputId": "4422783a-7beb-4f3d-81ba-07e24a645ad5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens= tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOaaZhKvEw-g",
        "outputId": "d60c3c27-55d9-4180-9eda-90ec4f5f2cde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'eu',\n",
              " 'rejects',\n",
              " 'german',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'british',\n",
              " 'lamb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " word_ids = tokenized_input.word_ids()"
      ],
      "metadata": {
        "id": "AQjsMwLzFEmo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxbg8C-6O6VL",
        "outputId": "434d3110-2b98-40c5-d1f4-6768166245a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, label in enumerate(example_text[\"ner_tags\"]):\n",
        "  print(i,label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R15UPSk-O8jS",
        "outputId": "0a3c97fb-ddfb-49d8-8cf7-dd31193a3419"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3\n",
            "1 0\n",
            "2 7\n",
            "3 0\n",
            "4 0\n",
            "5 0\n",
            "6 7\n",
            "7 0\n",
            "8 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "\n",
        "    #tokeinze ids\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "\n",
        "\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        # word_ids() => Return a list mapping the tokens\n",
        "        # to their actual word in the initial sentence.\n",
        "        # It Returns a list indicating the word corresponding to each token.\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        # Special tokens like `` and `<\\s>` are originally mapped to None\n",
        "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # set –100 as the label for these special tokens\n",
        "                label_ids.append(-100)\n",
        "\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # if current word_idx is != prev then its the most regular case\n",
        "                # and add the corresponding token\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # to take care of sub-words which have the same word_idx\n",
        "                # set -100 as well for them, but only if label_all_tokens == False\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "                # mask the subword representations after the first subword\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "hHmqbyYcSlxN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003[\"train\"][4:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miwdmRAHSytf",
        "outputId": "4ffb85ff-1045-4ac0-f2ce-526333d306c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': ['4'],\n",
              " 'tokens': [['Germany',\n",
              "   \"'s\",\n",
              "   'representative',\n",
              "   'to',\n",
              "   'the',\n",
              "   'European',\n",
              "   'Union',\n",
              "   \"'s\",\n",
              "   'veterinary',\n",
              "   'committee',\n",
              "   'Werner',\n",
              "   'Zwingmann',\n",
              "   'said',\n",
              "   'on',\n",
              "   'Wednesday',\n",
              "   'consumers',\n",
              "   'should',\n",
              "   'buy',\n",
              "   'sheepmeat',\n",
              "   'from',\n",
              "   'countries',\n",
              "   'other',\n",
              "   'than',\n",
              "   'Britain',\n",
              "   'until',\n",
              "   'the',\n",
              "   'scientific',\n",
              "   'advice',\n",
              "   'was',\n",
              "   'clearer',\n",
              "   '.']],\n",
              " 'pos_tags': [[22,\n",
              "   27,\n",
              "   21,\n",
              "   35,\n",
              "   12,\n",
              "   22,\n",
              "   22,\n",
              "   27,\n",
              "   16,\n",
              "   21,\n",
              "   22,\n",
              "   22,\n",
              "   38,\n",
              "   15,\n",
              "   22,\n",
              "   24,\n",
              "   20,\n",
              "   37,\n",
              "   21,\n",
              "   15,\n",
              "   24,\n",
              "   16,\n",
              "   15,\n",
              "   22,\n",
              "   15,\n",
              "   12,\n",
              "   16,\n",
              "   21,\n",
              "   38,\n",
              "   17,\n",
              "   7]],\n",
              " 'chunk_tags': [[11,\n",
              "   11,\n",
              "   12,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   21,\n",
              "   22,\n",
              "   11,\n",
              "   13,\n",
              "   11,\n",
              "   1,\n",
              "   13,\n",
              "   11,\n",
              "   17,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   1,\n",
              "   0]],\n",
              " 'ner_tags': [[5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   3,\n",
              "   4,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   2,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q= tokenize_and_align_labels(conll2003[\"train\"][4:5])"
      ],
      "metadata": {
        "id": "cgkc2mGOTCF_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n",
        "    print(f\"{token:_<40} {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWb6oTtwTe3G",
        "outputId": "c5c79597-53cb-4fe2-b51c-0765040b1bb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "germany_________________________________ 5\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "representative__________________________ 0\n",
            "to______________________________________ 0\n",
            "the_____________________________________ 0\n",
            "european________________________________ 3\n",
            "union___________________________________ 4\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "veterinary______________________________ 0\n",
            "committee_______________________________ 0\n",
            "werner__________________________________ 1\n",
            "z_______________________________________ 2\n",
            "##wing__________________________________ 2\n",
            "##mann__________________________________ 2\n",
            "said____________________________________ 0\n",
            "on______________________________________ 0\n",
            "wednesday_______________________________ 0\n",
            "consumers_______________________________ 0\n",
            "should__________________________________ 0\n",
            "buy_____________________________________ 0\n",
            "sheep___________________________________ 0\n",
            "##me____________________________________ 0\n",
            "##at____________________________________ 0\n",
            "from____________________________________ 0\n",
            "countries_______________________________ 0\n",
            "other___________________________________ 0\n",
            "than____________________________________ 0\n",
            "britain_________________________________ 5\n",
            "until___________________________________ 0\n",
            "the_____________________________________ 0\n",
            "scientific______________________________ 0\n",
            "advice__________________________________ 0\n",
            "was_____________________________________ 0\n",
            "clearer_________________________________ 0\n",
            "._______________________________________ 0\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying on entire data\n",
        "tokeized_dataset= conll2003.map(tokenize_and_align_labels,batched=True)"
      ],
      "metadata": {
        "id": "VKiRcqp4TtYB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokeized_dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgE2t2W1UbzA",
        "outputId": "2b72ebfc-ecfc-46de-cbc5-5e096562fc55"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
              " 'input_ids': [101,\n",
              "  7327,\n",
              "  19164,\n",
              "  2446,\n",
              "  2655,\n",
              "  2000,\n",
              "  17757,\n",
              "  2329,\n",
              "  12559,\n",
              "  1012,\n",
              "  102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AULNW3IgUnoo",
        "outputId": "2d4cc453-8644-4e18-a9ae-5c3287e43369"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "id": "h2m8z0OeVgKe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate - u"
      ],
      "metadata": {
        "id": "5kVZFvYhWJRT",
        "outputId": "79d70b43-987b-43b2-9201-0e0ec071975e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "\"test-ner\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=1,\n",
        "weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "DXAFsq2sVyDb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric= datasets.load_metric(\"seqeval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-xJ8O51Vgtt",
        "outputId": "a1083dbb-9b5c-4148-a177-a0623369fb6e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = conll2003[\"train\"][0]"
      ],
      "metadata": {
        "id": "MLZv2N8QW_o6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list= conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in2KCpEyXTd9",
        "outputId": "f4fb8a9b-aece-44ff-aebb-6915a90142a9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQx5yfdkXmUv",
        "outputId": "81ee6cab-a324-440e-d749-9a9020d6b1b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[labels],references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6jEUQWWX_AA",
        "outputId": "09e4032b-45b4-4a3d-8160-5d904165dc31"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don’t need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ],
      "metadata": {
        "id": "fX-b9CKIYnMZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator=DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "oHfr7lQvZiny"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer= Trainer(\n",
        "   model,\n",
        "   args,\n",
        "   train_dataset=tokeized_dataset[\"train\"],\n",
        "   eval_dataset=tokeized_dataset[\"validation\"],\n",
        "   data_collator = data_collator,\n",
        "   tokenizer=tokenizer,\n",
        "   compute_metrics= compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "uk_EtV2yZTSZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "bWEPLzOwZkrp",
        "outputId": "a10230bd-622f-40d8-c109-630a499a6814"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [878/878 02:39, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229000</td>\n",
              "      <td>0.071593</td>\n",
              "      <td>0.904820</td>\n",
              "      <td>0.919902</td>\n",
              "      <td>0.912298</td>\n",
              "      <td>0.980349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=878, training_loss=0.16719568726142067, metrics={'train_runtime': 161.9816, 'train_samples_per_second': 86.683, 'train_steps_per_second': 5.42, 'total_flos': 342221911376202.0, 'train_loss': 0.16719568726142067, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "SPbWm7zlaVPl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzF-bdFQbERk",
        "outputId": "0eba2a93-16c9-408e-c13b-c9f942d1eeed"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4txXV2OLbSj9",
        "outputId": "81060cf2-6e1e-48aa-9f7b-9d7b121339b6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    str(i): label for i,label in enumerate(label_list)\n",
        "}"
      ],
      "metadata": {
        "id": "8eq5tCPLbn37"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smE3-Y0cbnuR",
        "outputId": "d3725306-d49e-451f-a194-0fc6fd5a15f0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O',\n",
              " '1': 'B-PER',\n",
              " '2': 'I-PER',\n",
              " '3': 'B-ORG',\n",
              " '4': 'I-ORG',\n",
              " '5': 'B-LOC',\n",
              " '6': 'I-LOC',\n",
              " '7': 'B-MISC',\n",
              " '8': 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {\n",
        "    label: str(i) for i,label in enumerate(label_list)\n",
        "}"
      ],
      "metadata": {
        "id": "XMdY5BSBbnkC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g4r98yNbnWg",
        "outputId": "eb7fef44-4136-4260-a979-1cd85de3777b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': '0',\n",
              " 'B-PER': '1',\n",
              " 'I-PER': '2',\n",
              " 'B-ORG': '3',\n",
              " 'I-ORG': '4',\n",
              " 'B-LOC': '5',\n",
              " 'I-LOC': '6',\n",
              " 'B-MISC': '7',\n",
              " 'I-MISC': '8'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "5kciyFgxbnBh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = json.load(open(\"/content/ner_model/config.json\"))"
      ],
      "metadata": {
        "id": "JImlbGYIcltX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlLx7Td9clos",
        "outputId": "94bc3a63-6b94-4043-c693-0147fec13646"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_name_or_path': 'bert-base-uncased',\n",
              " 'architectures': ['BertForTokenClassification'],\n",
              " 'attention_probs_dropout_prob': 0.1,\n",
              " 'classifier_dropout': None,\n",
              " 'gradient_checkpointing': False,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'id2label': {'0': 'LABEL_0',\n",
              "  '1': 'LABEL_1',\n",
              "  '2': 'LABEL_2',\n",
              "  '3': 'LABEL_3',\n",
              "  '4': 'LABEL_4',\n",
              "  '5': 'LABEL_5',\n",
              "  '6': 'LABEL_6',\n",
              "  '7': 'LABEL_7',\n",
              "  '8': 'LABEL_8'},\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'label2id': {'LABEL_0': 0,\n",
              "  'LABEL_1': 1,\n",
              "  'LABEL_2': 2,\n",
              "  'LABEL_3': 3,\n",
              "  'LABEL_4': 4,\n",
              "  'LABEL_5': 5,\n",
              "  'LABEL_6': 6,\n",
              "  'LABEL_7': 7,\n",
              "  'LABEL_8': 8},\n",
              " 'layer_norm_eps': 1e-12,\n",
              " 'max_position_embeddings': 512,\n",
              " 'model_type': 'bert',\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'pad_token_id': 0,\n",
              " 'position_embedding_type': 'absolute',\n",
              " 'torch_dtype': 'float32',\n",
              " 'transformers_version': '4.35.2',\n",
              " 'type_vocab_size': 2,\n",
              " 'use_cache': True,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"id2label\"] = id2label\n"
      ],
      "metadata": {
        "id": "9gbZF5pFclkU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"label2id\"] = label2id"
      ],
      "metadata": {
        "id": "Ekeb6gxcclZ1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(config,open(\"/content/ner_model/config.json\",\"w\"))"
      ],
      "metadata": {
        "id": "h_hGvgcUclHR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine_tuned=AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "0KizsARZckma"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine_tuned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3qEjoKhdmZs",
        "outputId": "56e5e210-52a2-4eff-938f-d60a94d86129"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Pipeline"
      ],
      "metadata": {
        "id": "6rrBmybXbgyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "EyDNEwafbk25"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline= pipeline(\"ner\", model=model_fine_tuned, tokenizer= tokenizer)\n"
      ],
      "metadata": {
        "id": "36-hkG2BbvDJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example= \"Aaryan is founder of atrangi\""
      ],
      "metadata": {
        "id": "5EHmqtYIeTkC"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NJX-sN5fK-J",
        "outputId": "5a019d0e-bbb7-4d91-b467-12d6a1f7d6ee"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.97103006,\n",
              "  'index': 1,\n",
              "  'word': 'aa',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.97367585,\n",
              "  'index': 2,\n",
              "  'word': '##rya',\n",
              "  'start': 2,\n",
              "  'end': 5},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.9823271,\n",
              "  'index': 3,\n",
              "  'word': '##n',\n",
              "  'start': 5,\n",
              "  'end': 6},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.92694896,\n",
              "  'index': 7,\n",
              "  'word': 'at',\n",
              "  'start': 21,\n",
              "  'end': 23},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.9449967,\n",
              "  'index': 8,\n",
              "  'word': '##rang',\n",
              "  'start': 23,\n",
              "  'end': 27},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.9467024,\n",
              "  'index': 9,\n",
              "  'word': '##i',\n",
              "  'start': 27,\n",
              "  'end': 28}]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex= \"Aaryan is founder o google\""
      ],
      "metadata": {
        "id": "fz5b8uZmfPwZ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline(ex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgdynubRfn6t",
        "outputId": "98e91087-bd2f-4fb4-8f0e-c4715e07b237"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.9800116,\n",
              "  'index': 1,\n",
              "  'word': 'aa',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.9810971,\n",
              "  'index': 2,\n",
              "  'word': '##rya',\n",
              "  'start': 2,\n",
              "  'end': 5},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.98565024,\n",
              "  'index': 3,\n",
              "  'word': '##n',\n",
              "  'start': 5,\n",
              "  'end': 6},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.91402274,\n",
              "  'index': 7,\n",
              "  'word': 'google',\n",
              "  'start': 20,\n",
              "  'end': 26}]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=\"apple launch mobile while eating apple which taste like orange\"\n"
      ],
      "metadata": {
        "id": "Kp5ug4QGfqk8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Y9xw1wf7wk",
        "outputId": "afc89283-3bd5-4982-fa75-7655d4382063"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.86241174,\n",
              "  'index': 1,\n",
              "  'word': 'apple',\n",
              "  'start': 0,\n",
              "  'end': 5},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.83500206,\n",
              "  'index': 6,\n",
              "  'word': 'apple',\n",
              "  'start': 33,\n",
              "  'end': 38}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=\"Microsoft Windows created their software by idea that came from the window of the house\"\n"
      ],
      "metadata": {
        "id": "eeGj_unjf-F_"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWc1kXnvgQua",
        "outputId": "ff3ad7c9-6b96-42cc-9850-c6c3d053941c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.8962863,\n",
              "  'index': 1,\n",
              "  'word': 'microsoft',\n",
              "  'start': 0,\n",
              "  'end': 9},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.6467709,\n",
              "  'index': 2,\n",
              "  'word': 'windows',\n",
              "  'start': 10,\n",
              "  'end': 17}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdau7gbkgS74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}